{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO8 model\n",
    "model = YOLO(\"YOLOv8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to add each image of the dataset onto a manuscript background at a random position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_image(digit_image, background_image):\n",
    "    bg = cv2.imread(background_image)\n",
    "    digit = cv2.imread(digit_image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Resize digit and randomly place on the background\n",
    "    bg = cv2.resize(bg, (1500, 2000))\n",
    "    x, y = np.random.randint(0, bg.shape[1] - digit.shape[1]), np.random.randint(0, bg.shape[0] - digit.shape[0])\n",
    "    bg[y:y+digit.shape[0], x:x+digit.shape[1]] = digit\n",
    "\n",
    "    x_center = x + digit.shape[1] / 2\n",
    "    y_center = y + digit.shape[0] / 2\n",
    "    width = digit.shape[1]\n",
    "    height = digit.shape[0]\n",
    "\n",
    "    return bg, (x_center, y_center, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the create_synthetic_image function\n",
    "digit_image_path = '../datasets/DIDA/0/0_26.jpg'\n",
    "background_image_path = './white_background.jpg'\n",
    "\n",
    "synthetic_image, _ = create_synthetic_image(digit_image_path, background_image_path)\n",
    "\n",
    "# Display the synthetic image\n",
    "plt.imshow(cv2.cvtColor(synthetic_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test data with 2000 images from DIDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing digit 0...\n",
      "Done.\n",
      "Processing digit 1...\n",
      "Done.\n",
      "Processing digit 2...\n",
      "Done.\n",
      "Processing digit 3...\n",
      "Done.\n",
      "Processing digit 4...\n",
      "Done.\n",
      "Processing digit 5...\n",
      "Done.\n",
      "Processing digit 6...\n",
      "Done.\n",
      "Processing digit 7...\n",
      "Done.\n",
      "Processing digit 8...\n",
      "Done.\n",
      "Processing digit 9...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Define data size for each digit\n",
    "images_per_digit = 200\n",
    "\n",
    "# Define paths\n",
    "dataset_path = '../datasets/DIDA'\n",
    "train_path = './train'\n",
    "val_path = './val'\n",
    "\n",
    "# Create train and val directories\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "for digit in range(10):\n",
    "\tprint(f\"Processing digit {digit}...\")\n",
    "\tdigit_path = os.path.join(dataset_path, str(digit))\n",
    "\timages = [os.path.join(digit_path, img) for img in os.listdir(digit_path) if img.endswith('.jpg')]\n",
    "\timages_sample = np.random.choice(images, size=images_per_digit, replace=False)\n",
    "\ttrain_images, val_images = train_test_split(images_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "\tfor img in train_images:\n",
    "\t\tsynthetic_image, coord = create_synthetic_image(img, background_image_path)\n",
    "\t\t\t\t\n",
    "\t\timg_png = img.replace('.jpg', '.png')\n",
    "\t\tcv2.imwrite(os.path.join(train_path, f'{os.path.basename(img_png)}'), synthetic_image)\n",
    "\n",
    "\t\tlabel_file = img.replace('.jpg', '.txt')\n",
    "\t\tlabel_path = os.path.join(train_path, os.path.basename(label_file))\n",
    "\n",
    "\t\tlabel = f\"{digit} {coord[0] / 1500} {coord[1] / 2000} {coord[2] / 1500} {coord[3] / 2000}\"\n",
    "\n",
    "\t\twith open(label_path, 'w') as f:\n",
    "\t\t\tf.write(label)\n",
    "    \n",
    "\tfor img in val_images:\n",
    "\t\tsynthetic_image, coord = create_synthetic_image(img, background_image_path)\n",
    "\t\t\t\t\n",
    "\t\timg_png = img.replace('.jpg', '.png')\n",
    "\t\tcv2.imwrite(os.path.join(val_path, f'{os.path.basename(img_png)}'), synthetic_image)\n",
    "\n",
    "\t\tlabel_file = img.replace('.jpg', '.txt')\n",
    "\t\tlabel_path = os.path.join(val_path, os.path.basename(label_file))\n",
    "\n",
    "\t\tlabel = f\"{digit} {coord[0] / 1500} {coord[1] / 2000} {coord[2] / 1500} {coord[3] / 2000}\"\n",
    "\n",
    "\t\twith open(label_path, 'w') as f:\n",
    "\t\t\tf.write(label)\n",
    "    \n",
    "\tprint(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the YOLO configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the YOLO configuration file\n",
    "config = f\"\"\"\n",
    "train: {os.path.abspath(train_path)}\n",
    "val: {os.path.abspath(val_path)}\n",
    "\n",
    "nc: 10\n",
    "names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\"\"\"\n",
    "\n",
    "with open('DIDA.yaml', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.106 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.75  Python-3.9.13 torch-2.6.0+cpu CPU (Intel Core(TM) i5-9400F 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=YOLOv8n.pt, data=./DIDA.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A4\\PI2\\digits_detection_in_ancient_manuscripts\\test_with_yolo\\train... 1600 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1600/1600 [00:10<00:00, 154.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A4\\PI2\\digits_detection_in_ancient_manuscripts\\test_with_yolo\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A4\\PI2\\digits_detection_in_ancient_manuscripts\\test_with_yolo\\val... 400 images, 0 backgrounds, 0 corrupt: 100%|██████████| 400/400 [00:02<00:00, 162.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A4\\PI2\\digits_detection_in_ancient_manuscripts\\test_with_yolo\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.102      7.371     0.8068         14        640: 100%|██████████| 100/100 [08:41<00:00,  5.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:52<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400     0.0155      0.982      0.141      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G     0.8273      5.108     0.7987         15        640: 100%|██████████| 100/100 [08:17<00:00,  4.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:44<00:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.104      0.778      0.171      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G     0.7639      4.189     0.7931         16        640: 100%|██████████| 100/100 [08:26<00:00,  5.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:52<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.121       0.63      0.184       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G     0.6787      3.617     0.7991         11        640: 100%|██████████| 100/100 [09:30<00:00,  5.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:57<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.141      0.629       0.18      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G     0.6423      3.166     0.7867         16        640: 100%|██████████| 100/100 [08:36<00:00,  5.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:52<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.121      0.755       0.19      0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.5878      2.891     0.7877         15        640: 100%|██████████| 100/100 [08:30<00:00,  5.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:44<00:00,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.112      0.826      0.197      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.5627      2.669     0.7863         16        640: 100%|██████████| 100/100 [16:48<00:00, 10.09s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:57<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.128       0.83      0.208      0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.5392      2.555     0.7829         12        640: 100%|██████████| 100/100 [09:10<00:00,  5.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:57<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.134      0.747      0.222      0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.5104      2.436     0.7827         15        640: 100%|██████████| 100/100 [09:12<00:00,  5.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [01:14<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.137      0.696      0.241      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.4783      2.377     0.7818         13        640: 100%|██████████| 100/100 [10:44<00:00,  6.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:57<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.148       0.72      0.239      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 1.790 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.75  Python-3.9.13 torch-2.6.0+cpu CPU (Intel Core(TM) i5-9400F 2.90GHz)\n",
      "Model summary (fused): 168 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:42<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400        400      0.139      0.692      0.241      0.219\n",
      "                     0         40         40      0.169       0.55      0.257      0.218\n",
      "                     1         40         40      0.156      0.875      0.421      0.394\n",
      "                     2         40         40      0.108        0.6      0.139      0.124\n",
      "                     3         40         40      0.121      0.847      0.176      0.159\n",
      "                     4         40         40      0.101        0.7      0.121      0.107\n",
      "                     5         40         40      0.243      0.675      0.508      0.458\n",
      "                     6         40         40     0.0987      0.375      0.146      0.133\n",
      "                     7         40         40      0.131      0.725      0.199       0.19\n",
      "                     8         40         40      0.114      0.725      0.141      0.124\n",
      "                     9         40         40      0.145       0.85      0.301      0.279\n",
      "Speed: 1.7ms preprocess, 61.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data='./DIDA.yaml', epochs=10, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('yolo8_trained_on_dida.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pi2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
